{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d591c64-d2b6-4b90-b675-38e71ca8bc13",
   "metadata": {},
   "source": [
    "# Get center vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c52be9-e6e5-45ba-acaf-d7e6b3d21645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "df = pd.read_excel(\"/home/tuananh/tuananh/domain_calibration/experiments/resnet_34_kfold_val_outdomain_logits.xlsx\")\n",
    "domain_name = \"amazon\"\n",
    "df = df[df.domain_name == domain_name]\n",
    "df = df[df.phase == \"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c06c111-deea-49b0-8852-829959422962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1878, 31)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logit = np.vstack([json.loads(x) for x in df[\"logit\"].values])\n",
    "train_logit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da30b39-b463-4c9d-b430-34764d8ebaec",
   "metadata": {},
   "source": [
    "## Get mean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4bfe8c-ef32-4924-983a-d11670537a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# def default_collate(batch):\n",
    "#     batch = list(filter(lambda x: x is not None, batch))\n",
    "#     data_chest_cls = torch.stack([torch.tensor(item[0]) for item in batch])\n",
    "#     data_paths = [item[1] for item in batch]\n",
    "    \n",
    "#     return data_chest_cls, data_paths\n",
    "\n",
    "# class Dataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, image_paths):\n",
    "#         self.image_paths = image_paths\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         path = self.image_paths[index]\n",
    "#         image = np.array(Image.open(path).convert('RGB').resize((224, 224)))\n",
    "\n",
    "#         return image, path\n",
    "\n",
    "# params = {'batch_size': 100,\n",
    "#           'shuffle': True,\n",
    "#           'num_workers': 6}\n",
    "\n",
    "# data_set = Dataset(path_source)\n",
    "# data_generator = torch.utils.data.DataLoader(data_set, collate_fn=default_collate, **params)\n",
    "\n",
    "# def batch_mean(loader):\n",
    "#     nimages = 0\n",
    "#     mean = 0.\n",
    "#     for batch, path in tqdm(loader):\n",
    "#         batch = batch.permute(0, 3, 1, 2).float()\n",
    "#         # Rearrange batch to be the shape of [B, C, W * H]\n",
    "#         batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "#         # Update total number of images\n",
    "#         nimages += batch.size(0)\n",
    "#         # Compute mean and std here\n",
    "#         mean += batch.mean(2).sum(0)\n",
    "#     mean /= nimages\n",
    "\n",
    "#     return mean\n",
    "\n",
    "# mean = batch_mean(data_generator)\n",
    "# print(\"mean: \\n\", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff20169-d259-4b1c-8150-4e30ec5cc342",
   "metadata": {},
   "source": [
    "## Get mean feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48bd32fb-341d-4b29-a330-deaebd7f5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "from src.base_line.restnet34 import initialize_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1081e163-78ae-4196-a0ab-315ece8f0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import cv2\n",
    "\n",
    "\n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    return resized\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, df_info, folder_data, image_size_ratio, \n",
    "                input_size, transforms=None):\n",
    "        self.df_info = df_info\n",
    "        self.folder_data = folder_data\n",
    "        self.image_size_ratio = image_size_ratio\n",
    "        self.input_size = input_size\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_info)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        labels = self.df_info.iloc[index][\"classes\"]\n",
    "        image_id = self.df_info.iloc[index][\"imageid\"]\n",
    "\n",
    "        class_name = image_id.split(\"__\")[0]\n",
    "        image_name = image_id.split(\"__\")[1]\n",
    "\n",
    "        image_path = self.folder_data + \"/\" + image_id.split(\"__\")[0] + f\"/{image_name}\"\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = image_resize(image, width=self.image_size_ratio, height=self.image_size_ratio)\n",
    "        if image.shape[0] < 224 and image.shape[0] < 224:\n",
    "            image = cv2.resize(image, (self.input_size, self.input_size), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                \"image\": image\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample[\"image\"]\n",
    "\n",
    "        X = torch.Tensor(image).permute(2, 0, 1)\n",
    "        y = labels\n",
    "\n",
    "        return X, y, self.df_info.iloc[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fada776-0d95-4ed8-b1e8-83b46af5d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = initialize_model(\n",
    "    num_classes=31,\n",
    "    feature_extract=True, \n",
    "    use_pretrained=True\n",
    ")\n",
    "model_ft.fc = nn.Identity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab8df22b-1369-47a1-a542-1ff9f1baf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import main_thread\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# path = os.path.dirname(__file__)\n",
    "# root_folder = os.path.join(\n",
    "#     os.path.abspath(path).split(\"domain_calibration\")[0],\n",
    "#     \"domain_calibration\"\n",
    "# )\n",
    "# sys.path.insert(0, root_folder)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from src.base_line.data_loader_export_logits import Dataset\n",
    "from src.base_line.restnet34 import initialize_model\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_from_yaml(fname):\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        base_config = yaml.safe_load(f)\n",
    "    return base_config\n",
    "\n",
    "\n",
    "def get_agument(augment_name):\n",
    "    list_augment = []\n",
    "    for augment in augment_name:\n",
    "        if augment == \"CenterCrop\":\n",
    "            list_augment.append(\n",
    "                A.CenterCrop(width=224, height=224),\n",
    "            )\n",
    "        if augment == \"Flip\":\n",
    "            list_augment.append(\n",
    "                A.Flip(always_apply=False, p=0.5)\n",
    "            )\n",
    "        if augment == \"Blur\":\n",
    "            list_augment.append(\n",
    "                A.Blur(always_apply=False, p=0.5, blur_limit=(3, 7))\n",
    "            )\n",
    "        if augment == \"GaussNoise\":\n",
    "            list_augment.append(\n",
    "                A.GaussNoise(always_apply=False, p=0.5, var_limit=(10.0, 50.0))\n",
    "            )\n",
    "        if augment == \"RandomBrightness\":\n",
    "            list_augment.append(\n",
    "                A.RandomBrightness(\n",
    "                    always_apply=False, p=0.5, \n",
    "                    limit=(-0.20000000298023224, 0.20000000298023224))\n",
    "            )\n",
    "        if augment == \"Normalize\":\n",
    "            list_augment.append(\n",
    "                A.Normalize(\n",
    "                    mean=(0.485, 0.456, 0.406), \n",
    "                    std=(0.229, 0.224, 0.225)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return A.Compose(list_augment)\n",
    "\n",
    "\n",
    "def default_collate(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    images = torch.stack([torch.tensor(item[0]) for item in batch])\n",
    "    labels = torch.stack([torch.tensor(item[1]) for item in batch])\n",
    "    records = [item[2] for item in batch]\n",
    "    \n",
    "    return images, labels, records\n",
    "\n",
    "\n",
    "def export_features(\n",
    "    model, dataloaders, \n",
    "    export_main_domain=True):\n",
    "    \n",
    "    list_df = []\n",
    "    number_batch = 0\n",
    "    mean_vector = 0.\n",
    "    model.eval()\n",
    "    for inputs, labels, records in tqdm(dataloaders[phase]):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        mean_vector += outputs.view(inputs.size(0), -1).mean(0)\n",
    "        number_batch += 1\n",
    "\n",
    "        df = pd.DataFrame(records)\n",
    "        df[\"feature vector\"] = preds.cpu().detach().numpy().tolist()\n",
    "        list_df.append(df)\n",
    "    \n",
    "    mean_vector /= number_batch\n",
    "    df_result = pd.concat(list_df)\n",
    "    df_result[\"mean_feature_vector\"] = mean_vector.cpu().detach().numpy().tolist()\n",
    "    \n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eae4def-d2b4-4b33-9a0d-12764afa3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_params = load_from_yaml(\"./configs/exp.yaml\")\n",
    "\n",
    "for dataset_name in config_params[\"dataset_name\"]:\n",
    "    if dataset_name == \"Office-Home\":\n",
    "        path_information =\\\n",
    "            f\"{config_params['path_data']}/{dataset_name}/OfficeHomeDataset_10072016/information/\"\n",
    "    elif dataset_name == \"Bing-Caltech\":\n",
    "        path_information =\\\n",
    "            f\"{config_params['path_data']}/{dataset_name}/information/\"\n",
    "    else:\n",
    "        path_information =\\\n",
    "            f\"{config_params['path_data']}/{dataset_name}/information/\"\n",
    "\n",
    "    all_csv_domain = glob.glob(path_information + \"/*.csv\")\n",
    "    for path_csv in all_csv_domain:\n",
    "        main_domain = path_csv.split(\"/\")[-1].replace(\"_kfold.csv\", \"\")\n",
    "\n",
    "        print(f\"Running on {dataset_name} with domain: {main_domain} .... \")\n",
    "        path_weight_save =\\\n",
    "            f\"{config_params['path_save']}/{dataset_name}/{main_domain}/\"\n",
    "\n",
    "        if not os.path.isdir(path_weight_save):\n",
    "            os.makedirs(path_weight_save)\n",
    "\n",
    "        data_transforms = {\n",
    "            'train': get_agument(config_params[\"train_augment\"]),\n",
    "            'val': get_agument(config_params[\"val_augment\"])\n",
    "        }\n",
    "\n",
    "        print(\"Initializing Datasets and Dataloaders...\")\n",
    "        informations = [\n",
    "            {\n",
    "                \"dataframe\": pd.read_csv(path_csv),\n",
    "                \"domain_name\": path_csv.split(\"/\")[-1].replace(\"_kfold.csv\", \"\")\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        number_classes = len(set(informations[0][\"dataframe\"][\"classes\"]))\n",
    "\n",
    "        k_fold = 3\n",
    "        with pd.ExcelWriter(f'{path_weight_save}/resnet_34_export_feature_vector.xlsx') as writer:\n",
    "            for k in range(3):\n",
    "                if k in config_params[\"kfold_exp\"]:\n",
    "                    model_ft = initialize_model(\n",
    "                        num_classes=number_classes,\n",
    "                        feature_extract=True, \n",
    "                        use_pretrained=True\n",
    "                    )\n",
    "\n",
    "                    path_weight = path_weight_save + f\"resnet_34_kfold_{str(k)}.pth\"\n",
    "\n",
    "                    model_ft.load_state_dict(\n",
    "                        torch.load(\n",
    "                            path_weight,\n",
    "                            map_location=torch.device(device=device)\n",
    "                        )\n",
    "                    )\n",
    "                    model_ft.fc = nn.Identity()\n",
    "                    model_ft.eval()\n",
    "                    model_ft = model_ft.to(device)\n",
    "\n",
    "                    dataframe_logits = []\n",
    "                    for information in informations:\n",
    "                        domain_name = information[\"domain_name\"]\n",
    "                        if dataset_name ==  \"Office-Home\":\n",
    "                            path_root = f\"{config_params['path_data']}/{dataset_name}/OfficeHomeDataset_10072016/{domain_name}/\"\n",
    "                        elif dataset_name == \"Bing-Caltech\":\n",
    "                            path_root = f\"{config_params['path_data']}/{dataset_name}/BingLarge_C256_deduped/\"\n",
    "                        elif dataset_name == \"Domain-net\":\n",
    "                            path_root = f\"{config_params['path_data']}/{dataset_name}/{domain_name}/\"\n",
    "                        else:\n",
    "                            path_root = f\"{config_params['path_data']}/{dataset_name}/{domain_name}/images/\"\n",
    "\n",
    "                        df_info_k_fold = information[\"dataframe\"].copy()\n",
    "                        df_info_k_fold[\"domain_name\"] = domain_name\n",
    "                        df_info_k_fold[\"feature_vector\"] = np.nan\n",
    "                        df_info_k_fold[\"mean_feature_vector\"] = np.nan\n",
    "                        df_info_k_fold[\"phase\"] = \"train\"\n",
    "                        df_info_k_fold.loc[df_info_k_fold.kfold==k, ['phase']] = 'val'\n",
    "\n",
    "                        image_datasets = {\n",
    "                            \"train\": Dataset(\n",
    "                                df_info=df_info_k_fold[df_info_k_fold.phase==\"train\"],\n",
    "                                folder_data=path_root,\n",
    "                                image_size_ratio=config_params[\"image_size_ratio\"], \n",
    "                                input_size=config_params[\"input_size\"], \n",
    "                                transforms=data_transforms[\"train\"]),\n",
    "                            \"val\": Dataset(\n",
    "                                df_info=df_info_k_fold[df_info_k_fold.phase==\"val\"], \n",
    "                                folder_data=path_root,\n",
    "                                image_size_ratio=config_params[\"image_size_ratio\"], \n",
    "                                input_size=config_params[\"input_size\"],\n",
    "                                transforms=data_transforms[\"val\"]),\n",
    "                        }\n",
    "\n",
    "                        dataloaders_dict = {\n",
    "                            x: torch.utils.data.DataLoader(\n",
    "                                image_datasets[x],\n",
    "                                collate_fn=default_collate,\n",
    "                                batch_size=config_params[\"batch_size\"], \n",
    "                                shuffle=True, \n",
    "                                num_workers=config_params[\"num_workers\"]) for x in ['train', 'val']}\n",
    "\n",
    "                        if main_domain == domain_name:\n",
    "                            export_main_domain = True\n",
    "                        else:\n",
    "                            export_main_domain = False\n",
    "\n",
    "                        df_finish_pred = export_features(\n",
    "                            model_ft, dataloaders_dict, \n",
    "                            export_main_domain=export_main_domain,\n",
    "                        )\n",
    "\n",
    "                        dataframe_logits.append(df_finish_pred)\n",
    "\n",
    "                    dataframe_logits = pd.concat(dataframe_logits)\n",
    "                    dataframe_logits.to_excel(writer, sheet_name=f'kfold_{k}', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731d4bb-f1f8-4d1f-b5b0-2efe83ce3066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
